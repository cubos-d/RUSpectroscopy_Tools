{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "from datamodules import data_processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_archivo = \"../input_data/combi_500_100.csv\"\n",
    "path_rand1 = \"../input_data/uni_52500_1.csv\"\n",
    "path_rand2 = \"../input_data/uni_52500_2.csv\"\n",
    "path_rand3 = \"../input_data/uni_144489.csv\"\n",
    "path_rand4 = \"../input_data/uni_1414886.csv\"\n",
    "path_rand5 = \"../input_data/uni_2398582.csv\"\n",
    "datos_combi  = pd.read_csv(path_archivo)\n",
    "datos_rand1 = pd.read_csv(path_rand1)\n",
    "datos_rand2 = pd.read_csv(path_rand2)\n",
    "datos_rand3 = pd.read_csv(path_rand3)\n",
    "datos_rand4 = pd.read_csv(path_rand4)\n",
    "datos_rand5 = pd.read_csv(path_rand5)\n",
    "path_to_current_model = \"none\" #\"isotropico_act_custom.keras\" # colocar \"none\" si quiere entrenar un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_K</th>\n",
       "      <th>eta</th>\n",
       "      <th>beta</th>\n",
       "      <th>eig_0</th>\n",
       "      <th>eig_1</th>\n",
       "      <th>eig_2</th>\n",
       "      <th>eig_3</th>\n",
       "      <th>eig_4</th>\n",
       "      <th>eig_5</th>\n",
       "      <th>eig_6</th>\n",
       "      <th>...</th>\n",
       "      <th>eig_90</th>\n",
       "      <th>eig_91</th>\n",
       "      <th>eig_92</th>\n",
       "      <th>eig_93</th>\n",
       "      <th>eig_94</th>\n",
       "      <th>eig_95</th>\n",
       "      <th>eig_96</th>\n",
       "      <th>eig_97</th>\n",
       "      <th>eig_98</th>\n",
       "      <th>eig_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513461</td>\n",
       "      <td>0.520834</td>\n",
       "      <td>2.462206</td>\n",
       "      <td>0.034106</td>\n",
       "      <td>1.764647</td>\n",
       "      <td>3.465653</td>\n",
       "      <td>6.446372</td>\n",
       "      <td>9.886191</td>\n",
       "      <td>11.562449</td>\n",
       "      <td>14.789919</td>\n",
       "      <td>...</td>\n",
       "      <td>1073.047116</td>\n",
       "      <td>1082.426697</td>\n",
       "      <td>1102.042351</td>\n",
       "      <td>1151.160382</td>\n",
       "      <td>1151.722711</td>\n",
       "      <td>1193.775156</td>\n",
       "      <td>1208.780911</td>\n",
       "      <td>1219.344722</td>\n",
       "      <td>1224.141007</td>\n",
       "      <td>1225.155069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.453175</td>\n",
       "      <td>0.904978</td>\n",
       "      <td>0.678690</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>4.361191</td>\n",
       "      <td>8.879599</td>\n",
       "      <td>15.346436</td>\n",
       "      <td>18.378833</td>\n",
       "      <td>21.309113</td>\n",
       "      <td>31.472544</td>\n",
       "      <td>...</td>\n",
       "      <td>8589.366731</td>\n",
       "      <td>8740.973305</td>\n",
       "      <td>8745.939505</td>\n",
       "      <td>8813.854849</td>\n",
       "      <td>8957.763890</td>\n",
       "      <td>9360.001209</td>\n",
       "      <td>9441.588347</td>\n",
       "      <td>9498.228970</td>\n",
       "      <td>9600.635186</td>\n",
       "      <td>9771.157762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.305289</td>\n",
       "      <td>0.786018</td>\n",
       "      <td>1.750694</td>\n",
       "      <td>0.052944</td>\n",
       "      <td>1.738172</td>\n",
       "      <td>2.914895</td>\n",
       "      <td>6.154208</td>\n",
       "      <td>7.451840</td>\n",
       "      <td>9.088756</td>\n",
       "      <td>11.498754</td>\n",
       "      <td>...</td>\n",
       "      <td>476.043469</td>\n",
       "      <td>481.645629</td>\n",
       "      <td>493.045906</td>\n",
       "      <td>494.290833</td>\n",
       "      <td>498.284527</td>\n",
       "      <td>502.342678</td>\n",
       "      <td>527.075912</td>\n",
       "      <td>542.669933</td>\n",
       "      <td>547.161699</td>\n",
       "      <td>552.743847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116401</td>\n",
       "      <td>0.508804</td>\n",
       "      <td>1.561187</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>3.871294</td>\n",
       "      <td>4.498427</td>\n",
       "      <td>7.313661</td>\n",
       "      <td>16.944009</td>\n",
       "      <td>23.539851</td>\n",
       "      <td>25.482868</td>\n",
       "      <td>...</td>\n",
       "      <td>3110.277601</td>\n",
       "      <td>3245.658599</td>\n",
       "      <td>3246.520316</td>\n",
       "      <td>3306.172525</td>\n",
       "      <td>3374.102154</td>\n",
       "      <td>3633.979333</td>\n",
       "      <td>3663.903530</td>\n",
       "      <td>3699.166178</td>\n",
       "      <td>3719.122191</td>\n",
       "      <td>3730.560386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235985</td>\n",
       "      <td>1.262090</td>\n",
       "      <td>2.113612</td>\n",
       "      <td>0.269728</td>\n",
       "      <td>1.356214</td>\n",
       "      <td>2.259893</td>\n",
       "      <td>4.000866</td>\n",
       "      <td>4.099376</td>\n",
       "      <td>4.148445</td>\n",
       "      <td>5.161244</td>\n",
       "      <td>...</td>\n",
       "      <td>85.275208</td>\n",
       "      <td>85.336410</td>\n",
       "      <td>86.472296</td>\n",
       "      <td>87.721344</td>\n",
       "      <td>88.834995</td>\n",
       "      <td>92.506316</td>\n",
       "      <td>94.098947</td>\n",
       "      <td>94.165783</td>\n",
       "      <td>95.719851</td>\n",
       "      <td>96.214931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_K       eta      beta     eig_0     eig_1     eig_2      eig_3  \\\n",
       "0  0.513461  0.520834  2.462206  0.034106  1.764647  3.465653   6.446372   \n",
       "1  1.453175  0.904978  0.678690  0.008021  4.361191  8.879599  15.346436   \n",
       "2  0.305289  0.786018  1.750694  0.052944  1.738172  2.914895   6.154208   \n",
       "3  0.116401  0.508804  1.561187  0.002957  3.871294  4.498427   7.313661   \n",
       "4  0.235985  1.262090  2.113612  0.269728  1.356214  2.259893   4.000866   \n",
       "\n",
       "       eig_4      eig_5      eig_6  ...       eig_90       eig_91  \\\n",
       "0   9.886191  11.562449  14.789919  ...  1073.047116  1082.426697   \n",
       "1  18.378833  21.309113  31.472544  ...  8589.366731  8740.973305   \n",
       "2   7.451840   9.088756  11.498754  ...   476.043469   481.645629   \n",
       "3  16.944009  23.539851  25.482868  ...  3110.277601  3245.658599   \n",
       "4   4.099376   4.148445   5.161244  ...    85.275208    85.336410   \n",
       "\n",
       "        eig_92       eig_93       eig_94       eig_95       eig_96  \\\n",
       "0  1102.042351  1151.160382  1151.722711  1193.775156  1208.780911   \n",
       "1  8745.939505  8813.854849  8957.763890  9360.001209  9441.588347   \n",
       "2   493.045906   494.290833   498.284527   502.342678   527.075912   \n",
       "3  3246.520316  3306.172525  3374.102154  3633.979333  3663.903530   \n",
       "4    86.472296    87.721344    88.834995    92.506316    94.098947   \n",
       "\n",
       "        eig_97       eig_98       eig_99  \n",
       "0  1219.344722  1224.141007  1225.155069  \n",
       "1  9498.228970  9600.635186  9771.157762  \n",
       "2   542.669933   547.161699   552.743847  \n",
       "3  3699.166178  3719.122191  3730.560386  \n",
       "4    94.165783    95.719851    96.214931  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_rand1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_combi = datos_combi.sort_values(by=[\"eta\", \"beta\", \"phi_K\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_eig = 5\n",
    "features = [\"eta\", \"beta\"] + list(map(lambda x: \"eig_\" + str(x+1), range(N_eig)))\n",
    "target = \"phi_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_combi = data_processors.preprocess_data(datos_combi, N_eig, target)\n",
    "datos_rand1 = data_processors.preprocess_data(datos_rand1, N_eig, target)\n",
    "datos_rand2 = data_processors.preprocess_data(datos_rand2, N_eig, target)\n",
    "datos_rand3 = data_processors.preprocess_data(datos_rand3, N_eig, target)\n",
    "datos_rand4 = data_processors.preprocess_data(datos_rand4, N_eig, target)\n",
    "datos_rand5 = data_processors.preprocess_data(datos_rand5, N_eig, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_K</th>\n",
       "      <th>eig_0</th>\n",
       "      <th>eta</th>\n",
       "      <th>beta</th>\n",
       "      <th>eig_1</th>\n",
       "      <th>eig_2</th>\n",
       "      <th>eig_3</th>\n",
       "      <th>eig_4</th>\n",
       "      <th>eig_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.326879</td>\n",
       "      <td>0.034106</td>\n",
       "      <td>0.520834</td>\n",
       "      <td>2.462206</td>\n",
       "      <td>0.566686</td>\n",
       "      <td>0.509182</td>\n",
       "      <td>0.537613</td>\n",
       "      <td>0.652058</td>\n",
       "      <td>0.855026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.925120</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.904978</td>\n",
       "      <td>0.678690</td>\n",
       "      <td>0.229295</td>\n",
       "      <td>0.491147</td>\n",
       "      <td>0.578610</td>\n",
       "      <td>0.835006</td>\n",
       "      <td>0.862487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194353</td>\n",
       "      <td>0.052944</td>\n",
       "      <td>0.786018</td>\n",
       "      <td>1.750694</td>\n",
       "      <td>0.575317</td>\n",
       "      <td>0.596307</td>\n",
       "      <td>0.473643</td>\n",
       "      <td>0.825864</td>\n",
       "      <td>0.819897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.074103</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.508804</td>\n",
       "      <td>1.561187</td>\n",
       "      <td>0.258312</td>\n",
       "      <td>0.860588</td>\n",
       "      <td>0.615072</td>\n",
       "      <td>0.431637</td>\n",
       "      <td>0.719801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150232</td>\n",
       "      <td>0.269728</td>\n",
       "      <td>1.262090</td>\n",
       "      <td>2.113612</td>\n",
       "      <td>0.737347</td>\n",
       "      <td>0.600123</td>\n",
       "      <td>0.564851</td>\n",
       "      <td>0.975970</td>\n",
       "      <td>0.988172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_K     eig_0       eta      beta     eig_1     eig_2     eig_3  \\\n",
       "0  0.326879  0.034106  0.520834  2.462206  0.566686  0.509182  0.537613   \n",
       "1  0.925120  0.008021  0.904978  0.678690  0.229295  0.491147  0.578610   \n",
       "2  0.194353  0.052944  0.786018  1.750694  0.575317  0.596307  0.473643   \n",
       "3  0.074103  0.002957  0.508804  1.561187  0.258312  0.860588  0.615072   \n",
       "4  0.150232  0.269728  1.262090  2.113612  0.737347  0.600123  0.564851   \n",
       "\n",
       "      eig_4     eig_5  \n",
       "0  0.652058  0.855026  \n",
       "1  0.835006  0.862487  \n",
       "2  0.825864  0.819897  \n",
       "3  0.431637  0.719801  \n",
       "4  0.975970  0.988172  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_rand1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'combi': 52500, 'rand1': 52494, 'rand2': 52493}\n"
     ]
    }
   ],
   "source": [
    "metadata_temporal = {\"combi\": len(datos_combi), \"rand1\": len(datos_rand1), \"rand2\": len(datos_rand2)}\n",
    "print(metadata_temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "N_phi_K = 500\n",
    "N_datos = len(datos_combi)\n",
    "N_partes = int(N_datos/N_phi_K)\n",
    "print(N_partes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combi = datos_combi[features]\n",
    "X_rand1 = datos_rand1[features]\n",
    "X_rand2 = datos_rand2[features]\n",
    "X_rand3 = datos_rand3[features]\n",
    "X_rand4 = datos_rand4[features]\n",
    "X_rand5 = datos_rand5[features]\n",
    "y_combi = datos_combi[target]\n",
    "y_rand1 = datos_rand1[target]\n",
    "y_rand2 = datos_rand2[target]\n",
    "y_rand3 = datos_rand3[target]\n",
    "y_rand4 = datos_rand4[target]\n",
    "y_rand5 = datos_rand5[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat((X_rand2, X_rand3, X_rand4), axis = 0)\n",
    "y_train = pd.concat((y_rand2, y_rand3, y_rand4), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            eta      beta     eig_1     eig_2     eig_3     eig_4     eig_5\n",
      "eta    1.000000 -0.000852  0.512913  0.135232  0.177204  0.489793  0.250627\n",
      "beta  -0.000852  1.000000  0.423466  0.479268 -0.266167  0.173364  0.520665\n",
      "eig_1  0.512913  0.423466  1.000000 -0.114866  0.034929  0.408786  0.396506\n",
      "eig_2  0.135232  0.479268 -0.114866  1.000000 -0.582443  0.050571  0.322903\n",
      "eig_3  0.177204 -0.266167  0.034929 -0.582443  1.000000 -0.236667 -0.098911\n",
      "eig_4  0.489793  0.173364  0.408786  0.050571 -0.236667  1.000000 -0.019070\n",
      "eig_5  0.250627  0.520665  0.396506  0.322903 -0.098911 -0.019070  1.000000\n"
     ]
    }
   ],
   "source": [
    "corr_mat = X_train.select_dtypes(include=['number']).corr()\n",
    "print(corr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correlation Matrix')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(corr_mat, cmap=sns.diverging_palette(220, 10, as_cmap=True))\n",
    "plt.title(\"Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='AMD Radeon RX 6600M', major=10, minor=3, gcnArchName='gfx1030', total_memory=8176MB, multi_processor_count=14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pow = 20\n",
    "def custom_activation(x):\n",
    "    return (1/n_pow) * torch.log((1 + torch.exp(n_pow * x)) / (1 + torch.exp(n_pow * (x - 1))))\n",
    "#fin función\n",
    "\n",
    "# Wrap the function in a Keras custom layer\n",
    "@keras.saving.register_keras_serializable()\n",
    "class CustomActivationLayer(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomActivationLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Ensure inputs are Torch tensors\n",
    "        inputs = torch.tensor(inputs) if not isinstance(inputs, torch.Tensor) else inputs\n",
    "        return custom_activation(inputs)\n",
    "    #fin función\n",
    "#fin clase\n",
    "\n",
    "def crear_modelo_de_regresion(lr_var, n_input_data):    \n",
    "    modelo = keras.models.Sequential()\n",
    "    modelo.add(keras.layers.Dense(64, activation = 'relu', input_shape = (n_input_data,)))\n",
    "    modelo.add(keras.layers.Dense(32, activation = 'relu'))\n",
    "    modelo.add(keras.layers.Dense(16, activation = 'relu'))\n",
    "    modelo.add(keras.layers.Dense(4, activation = 'relu'))\n",
    "    modelo.add(keras.layers.Dense(1))\n",
    "    modelo.add(CustomActivationLayer())\n",
    "    modelo.compile(optimizer = keras.optimizers.RMSprop(learning_rate = lr_var), loss = 'mse', metrics = ['mae'])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4 #4 sets de validación\n",
    "n_muestras_val = len(X_train) // k\n",
    "epocas = 20\n",
    "all_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cubos/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0408 - mae: 0.1543 - val_loss: 0.0120 - val_mae: 0.0819\n",
      "Epoch 2/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0783 - val_loss: 0.0072 - val_mae: 0.0553\n",
      "Epoch 3/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0629 - val_loss: 0.0062 - val_mae: 0.0478\n",
      "Epoch 4/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0069 - mae: 0.0551 - val_loss: 0.0063 - val_mae: 0.0565\n",
      "Epoch 5/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - loss: 0.0059 - mae: 0.0496 - val_loss: 0.0088 - val_mae: 0.0658\n",
      "Epoch 6/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - loss: 0.0052 - mae: 0.0455 - val_loss: 0.0047 - val_mae: 0.0425\n",
      "Epoch 7/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0046 - mae: 0.0423 - val_loss: 0.0038 - val_mae: 0.0343\n",
      "Epoch 8/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - loss: 0.0042 - mae: 0.0405 - val_loss: 0.0037 - val_mae: 0.0334\n",
      "Epoch 9/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0385 - val_loss: 0.0024 - val_mae: 0.0293\n",
      "Epoch 10/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0368 - val_loss: 0.0023 - val_mae: 0.0283\n",
      "Epoch 11/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0360 - val_loss: 0.0038 - val_mae: 0.0392\n",
      "Epoch 12/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0347 - val_loss: 0.0039 - val_mae: 0.0354\n",
      "Epoch 13/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0342 - val_loss: 0.0018 - val_mae: 0.0240\n",
      "Epoch 14/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0334 - val_loss: 0.0029 - val_mae: 0.0304\n",
      "Epoch 15/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0326 - val_loss: 0.0039 - val_mae: 0.0388\n",
      "Epoch 16/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0319 - val_loss: 0.0021 - val_mae: 0.0270\n",
      "Epoch 17/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0316 - val_loss: 0.0024 - val_mae: 0.0276\n",
      "Epoch 18/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0308 - val_loss: 0.0025 - val_mae: 0.0288\n",
      "Epoch 19/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0305 - val_loss: 0.0021 - val_mae: 0.0263\n",
      "Epoch 20/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0300 - val_loss: 0.0024 - val_mae: 0.0285\n",
      "Epoch 21/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0295 - val_loss: 0.0035 - val_mae: 0.0363\n",
      "Epoch 22/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0292 - val_loss: 0.0017 - val_mae: 0.0222\n",
      "Epoch 23/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0288 - val_loss: 0.0046 - val_mae: 0.0359\n",
      "Epoch 24/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0023 - mae: 0.0283 - val_loss: 0.0023 - val_mae: 0.0262\n",
      "Epoch 25/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0023 - mae: 0.0281 - val_loss: 0.0016 - val_mae: 0.0209\n",
      "Epoch 26/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0023 - mae: 0.0279 - val_loss: 0.0015 - val_mae: 0.0201\n",
      "Epoch 27/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0022 - mae: 0.0273 - val_loss: 0.0026 - val_mae: 0.0298\n",
      "Epoch 28/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0022 - mae: 0.0269 - val_loss: 0.0047 - val_mae: 0.0425\n",
      "Epoch 29/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0021 - mae: 0.0267 - val_loss: 0.0016 - val_mae: 0.0230\n",
      "Epoch 30/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0021 - mae: 0.0266 - val_loss: 0.0023 - val_mae: 0.0324\n",
      "Epoch 31/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0021 - mae: 0.0264 - val_loss: 0.0013 - val_mae: 0.0186\n",
      "Epoch 32/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0020 - mae: 0.0260 - val_loss: 0.0032 - val_mae: 0.0326\n",
      "Epoch 33/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0020 - mae: 0.0260 - val_loss: 0.0030 - val_mae: 0.0333\n",
      "Epoch 34/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0021 - mae: 0.0259 - val_loss: 0.0016 - val_mae: 0.0203\n",
      "Epoch 35/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0020 - mae: 0.0257 - val_loss: 0.0018 - val_mae: 0.0224\n",
      "Epoch 36/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0020 - mae: 0.0253 - val_loss: 0.0019 - val_mae: 0.0270\n",
      "Epoch 37/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0020 - mae: 0.0251 - val_loss: 0.0029 - val_mae: 0.0287\n",
      "Epoch 38/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0249 - val_loss: 0.0016 - val_mae: 0.0232\n",
      "Epoch 39/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0247 - val_loss: 0.0016 - val_mae: 0.0208\n",
      "Epoch 40/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0247 - val_loss: 0.0014 - val_mae: 0.0213\n",
      "Epoch 41/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0019 - mae: 0.0247 - val_loss: 0.0016 - val_mae: 0.0242\n",
      "Epoch 42/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0245 - val_loss: 0.0013 - val_mae: 0.0184\n",
      "Epoch 43/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0018 - mae: 0.0245 - val_loss: 0.0014 - val_mae: 0.0209\n",
      "Epoch 44/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0241 - val_loss: 0.0018 - val_mae: 0.0211\n",
      "Epoch 45/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0241 - val_loss: 0.0018 - val_mae: 0.0247\n",
      "Epoch 46/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0019 - mae: 0.0240 - val_loss: 0.0017 - val_mae: 0.0214\n",
      "Epoch 47/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0239 - val_loss: 0.0017 - val_mae: 0.0217\n",
      "Epoch 48/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0237 - val_loss: 0.0025 - val_mae: 0.0260\n",
      "Epoch 49/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0238 - val_loss: 0.0033 - val_mae: 0.0339\n",
      "Epoch 50/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0234 - val_loss: 0.0017 - val_mae: 0.0210\n",
      "Epoch 51/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0234 - val_loss: 0.0018 - val_mae: 0.0209\n",
      "Epoch 52/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0234 - val_loss: 0.0017 - val_mae: 0.0238\n",
      "Epoch 53/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0232 - val_loss: 0.0015 - val_mae: 0.0214\n",
      "Epoch 54/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0231 - val_loss: 0.0020 - val_mae: 0.0269\n",
      "Epoch 55/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0017 - mae: 0.0230 - val_loss: 0.0019 - val_mae: 0.0232\n",
      "Epoch 56/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0231 - val_loss: 0.0013 - val_mae: 0.0198\n",
      "Epoch 57/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0228 - val_loss: 0.0014 - val_mae: 0.0211\n",
      "Epoch 58/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0229 - val_loss: 0.0013 - val_mae: 0.0170\n",
      "Epoch 59/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0017 - mae: 0.0229 - val_loss: 0.0018 - val_mae: 0.0246\n",
      "Epoch 60/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0228 - val_loss: 0.0018 - val_mae: 0.0253\n",
      "Epoch 61/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0227 - val_loss: 0.0015 - val_mae: 0.0231\n",
      "Epoch 62/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0016 - mae: 0.0226 - val_loss: 0.0011 - val_mae: 0.0173\n",
      "Epoch 63/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0011 - val_mae: 0.0170\n",
      "Epoch 64/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0225 - val_loss: 0.0016 - val_mae: 0.0235\n",
      "Epoch 65/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0024 - val_mae: 0.0283\n",
      "Epoch 66/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0017 - val_mae: 0.0212\n",
      "Epoch 67/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0016 - mae: 0.0225 - val_loss: 0.0010 - val_mae: 0.0156\n",
      "Epoch 68/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0222 - val_loss: 0.0015 - val_mae: 0.0185\n",
      "Epoch 69/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0015 - val_mae: 0.0212\n",
      "Epoch 70/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0223 - val_loss: 0.0013 - val_mae: 0.0189\n",
      "Epoch 71/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0221 - val_loss: 0.0015 - val_mae: 0.0207\n",
      "Epoch 72/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0219 - val_loss: 0.0011 - val_mae: 0.0170\n",
      "Epoch 73/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0220 - val_loss: 0.0014 - val_mae: 0.0203\n",
      "Epoch 74/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0015 - mae: 0.0220 - val_loss: 0.0012 - val_mae: 0.0190\n",
      "Epoch 75/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0022 - val_mae: 0.0286\n",
      "Epoch 76/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0220 - val_loss: 0.0015 - val_mae: 0.0226\n",
      "Epoch 77/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0012 - val_mae: 0.0170\n",
      "Epoch 78/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0015 - val_mae: 0.0245\n",
      "Epoch 79/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0216 - val_loss: 0.0012 - val_mae: 0.0171\n",
      "Epoch 80/80\n",
      "\u001b[1m9629/9629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0217 - val_loss: 0.0017 - val_mae: 0.0255\n"
     ]
    }
   ],
   "source": [
    "if path_to_current_model == \"none\":\n",
    "    modelo = crear_modelo_de_regresion(0.001, len(features))\n",
    "    history = modelo.fit(X_train, y_train, epochs = epocas, batch_size=16, \n",
    "                            validation_data = (X_rand5, y_rand5))\n",
    "else:\n",
    "    modelo = keras.models.load_model(path_to_current_model)\n",
    "#fin if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4815/4815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "\u001b[1m1587/1587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "mets_train = data_processors.get_metrics(X_train, y_train, modelo)\n",
    "mets_val = data_processors.get_metrics(X_rand5, y_rand5, modelo)\n",
    "mets_rand1 = data_processors.get_metrics(X_rand1, y_rand1, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  {'R2': 0.9790051621822474, 'RMSE': np.float64(0.04182395630651085), 'MAE': np.float64(0.025542308717080058)}\n",
      "Val:  {'R2': 0.9792836199268861, 'RMSE': np.float64(0.041489707995164174), 'MAE': np.float64(0.02545270680776496)}\n",
      "Test:  {'R2': 0.9786800424732258, 'RMSE': np.float64(0.04216437349726116), 'MAE': np.float64(0.025559416557300332)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", mets_train)\n",
    "print(\"Val: \", mets_val)\n",
    "print(\"Test: \", mets_rand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_archivo_kg = \"../input_data/KG_random.csv\"\n",
    "str_to_ndarray = lambda x: np.fromstring(x, sep=' ')\n",
    "datos_kg_random = pd.read_csv(path_archivo_kg, converters={'eigvals': str_to_ndarray})\n",
    "datos_kg_random = datos_kg_random[datos_kg_random[\"shape\"] == \"parallelepiped\"].copy()\n",
    "datos_kg_random_std = data_processors.transform_full_sized_data_isotropic(datos_kg_random, N_eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>G</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dz</th>\n",
       "      <th>shape</th>\n",
       "      <th>eig_0</th>\n",
       "      <th>eig_1</th>\n",
       "      <th>eig_2</th>\n",
       "      <th>eig_3</th>\n",
       "      <th>eig_4</th>\n",
       "      <th>eig_5</th>\n",
       "      <th>phi_K</th>\n",
       "      <th>eta</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98304</th>\n",
       "      <td>1.137564</td>\n",
       "      <td>0.925310</td>\n",
       "      <td>0.345791</td>\n",
       "      <td>0.722980</td>\n",
       "      <td>0.454774</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>0.412707</td>\n",
       "      <td>0.524816</td>\n",
       "      <td>0.664249</td>\n",
       "      <td>1.242484</td>\n",
       "      <td>1.352123</td>\n",
       "      <td>1.526493</td>\n",
       "      <td>0.682866</td>\n",
       "      <td>1.337486</td>\n",
       "      <td>2.600392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98305</th>\n",
       "      <td>5.500412</td>\n",
       "      <td>5.321621</td>\n",
       "      <td>0.402060</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>0.807374</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>1.582053</td>\n",
       "      <td>2.487298</td>\n",
       "      <td>4.468703</td>\n",
       "      <td>4.838954</td>\n",
       "      <td>5.974758</td>\n",
       "      <td>6.092165</td>\n",
       "      <td>0.768879</td>\n",
       "      <td>1.468138</td>\n",
       "      <td>1.848136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98306</th>\n",
       "      <td>3.375617</td>\n",
       "      <td>3.980662</td>\n",
       "      <td>0.429638</td>\n",
       "      <td>0.851665</td>\n",
       "      <td>0.529495</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>1.910220</td>\n",
       "      <td>2.281837</td>\n",
       "      <td>2.722189</td>\n",
       "      <td>5.154925</td>\n",
       "      <td>5.985199</td>\n",
       "      <td>6.880495</td>\n",
       "      <td>0.867462</td>\n",
       "      <td>1.350259</td>\n",
       "      <td>2.726644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98307</th>\n",
       "      <td>1.448420</td>\n",
       "      <td>4.074601</td>\n",
       "      <td>0.151318</td>\n",
       "      <td>0.942633</td>\n",
       "      <td>0.328977</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>0.077098</td>\n",
       "      <td>0.249390</td>\n",
       "      <td>0.259526</td>\n",
       "      <td>0.483552</td>\n",
       "      <td>0.808482</td>\n",
       "      <td>1.025586</td>\n",
       "      <td>1.229252</td>\n",
       "      <td>0.733530</td>\n",
       "      <td>1.724437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98308</th>\n",
       "      <td>0.351677</td>\n",
       "      <td>5.407791</td>\n",
       "      <td>0.446276</td>\n",
       "      <td>0.792512</td>\n",
       "      <td>0.989446</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>0.665386</td>\n",
       "      <td>1.100423</td>\n",
       "      <td>1.220930</td>\n",
       "      <td>1.825798</td>\n",
       "      <td>2.004655</td>\n",
       "      <td>2.115424</td>\n",
       "      <td>1.505856</td>\n",
       "      <td>1.486674</td>\n",
       "      <td>2.051426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131067</th>\n",
       "      <td>0.603325</td>\n",
       "      <td>3.002608</td>\n",
       "      <td>0.720661</td>\n",
       "      <td>0.439132</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>0.138335</td>\n",
       "      <td>0.260256</td>\n",
       "      <td>0.492664</td>\n",
       "      <td>0.812795</td>\n",
       "      <td>0.834834</td>\n",
       "      <td>0.876376</td>\n",
       "      <td>1.372503</td>\n",
       "      <td>1.145569</td>\n",
       "      <td>1.334456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131068</th>\n",
       "      <td>2.302202</td>\n",
       "      <td>2.474801</td>\n",
       "      <td>0.132153</td>\n",
       "      <td>0.607512</td>\n",
       "      <td>0.605882</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>0.140488</td>\n",
       "      <td>0.296209</td>\n",
       "      <td>0.339297</td>\n",
       "      <td>0.719497</td>\n",
       "      <td>0.721766</td>\n",
       "      <td>1.428381</td>\n",
       "      <td>0.821514</td>\n",
       "      <td>1.591347</td>\n",
       "      <td>0.859013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131069</th>\n",
       "      <td>4.789391</td>\n",
       "      <td>3.091901</td>\n",
       "      <td>0.174914</td>\n",
       "      <td>0.402842</td>\n",
       "      <td>0.230977</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>1.185878</td>\n",
       "      <td>1.416827</td>\n",
       "      <td>1.833425</td>\n",
       "      <td>3.694734</td>\n",
       "      <td>4.251125</td>\n",
       "      <td>4.515988</td>\n",
       "      <td>0.573257</td>\n",
       "      <td>1.247024</td>\n",
       "      <td>2.592575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131070</th>\n",
       "      <td>0.920026</td>\n",
       "      <td>0.420177</td>\n",
       "      <td>0.185685</td>\n",
       "      <td>0.716565</td>\n",
       "      <td>0.322597</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>0.054970</td>\n",
       "      <td>0.067623</td>\n",
       "      <td>0.107235</td>\n",
       "      <td>0.267023</td>\n",
       "      <td>0.267814</td>\n",
       "      <td>0.273033</td>\n",
       "      <td>0.428413</td>\n",
       "      <td>0.958174</td>\n",
       "      <td>2.089119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131071</th>\n",
       "      <td>2.173239</td>\n",
       "      <td>2.870167</td>\n",
       "      <td>0.191433</td>\n",
       "      <td>0.890620</td>\n",
       "      <td>0.323195</td>\n",
       "      <td>parallelepiped</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>0.331292</td>\n",
       "      <td>0.331488</td>\n",
       "      <td>0.879808</td>\n",
       "      <td>1.059884</td>\n",
       "      <td>1.309372</td>\n",
       "      <td>0.922714</td>\n",
       "      <td>0.798260</td>\n",
       "      <td>2.138992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32768 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               K         G        dx        dy        dz           shape  \\\n",
       "98304   1.137564  0.925310  0.345791  0.722980  0.454774  parallelepiped   \n",
       "98305   5.500412  5.321621  0.402060  0.999638  0.807374  parallelepiped   \n",
       "98306   3.375617  3.980662  0.429638  0.851665  0.529495  parallelepiped   \n",
       "98307   1.448420  4.074601  0.151318  0.942633  0.328977  parallelepiped   \n",
       "98308   0.351677  5.407791  0.446276  0.792512  0.989446  parallelepiped   \n",
       "...          ...       ...       ...       ...       ...             ...   \n",
       "131067  0.603325  3.002608  0.720661  0.439132  0.152189  parallelepiped   \n",
       "131068  2.302202  2.474801  0.132153  0.607512  0.605882  parallelepiped   \n",
       "131069  4.789391  3.091901  0.174914  0.402842  0.230977  parallelepiped   \n",
       "131070  0.920026  0.420177  0.185685  0.716565  0.322597  parallelepiped   \n",
       "131071  2.173239  2.870167  0.191433  0.890620  0.323195  parallelepiped   \n",
       "\n",
       "           eig_0     eig_1     eig_2     eig_3     eig_4     eig_5     phi_K  \\\n",
       "98304   0.412707  0.524816  0.664249  1.242484  1.352123  1.526493  0.682866   \n",
       "98305   1.582053  2.487298  4.468703  4.838954  5.974758  6.092165  0.768879   \n",
       "98306   1.910220  2.281837  2.722189  5.154925  5.985199  6.880495  0.867462   \n",
       "98307   0.077098  0.249390  0.259526  0.483552  0.808482  1.025586  1.229252   \n",
       "98308   0.665386  1.100423  1.220930  1.825798  2.004655  2.115424  1.505856   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "131067  0.138335  0.260256  0.492664  0.812795  0.834834  0.876376  1.372503   \n",
       "131068  0.140488  0.296209  0.339297  0.719497  0.721766  1.428381  0.821514   \n",
       "131069  1.185878  1.416827  1.833425  3.694734  4.251125  4.515988  0.573257   \n",
       "131070  0.054970  0.067623  0.107235  0.267023  0.267814  0.273033  0.428413   \n",
       "131071  0.160311  0.331292  0.331488  0.879808  1.059884  1.309372  0.922714   \n",
       "\n",
       "             eta      beta  \n",
       "98304   1.337486  2.600392  \n",
       "98305   1.468138  1.848136  \n",
       "98306   1.350259  2.726644  \n",
       "98307   0.733530  1.724437  \n",
       "98308   1.486674  2.051426  \n",
       "...          ...       ...  \n",
       "131067  1.145569  1.334456  \n",
       "131068  1.591347  0.859013  \n",
       "131069  1.247024  2.592575  \n",
       "131070  0.958174  2.089119  \n",
       "131071  0.798260  2.138992  \n",
       "\n",
       "[32768 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_kg_random_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_kg_random_copy = data_processors.preprocess_data(datos_kg_random_std, N_eig, target, opt = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_K</th>\n",
       "      <th>eig_0</th>\n",
       "      <th>eta</th>\n",
       "      <th>beta</th>\n",
       "      <th>eig_1</th>\n",
       "      <th>eig_2</th>\n",
       "      <th>eig_3</th>\n",
       "      <th>eig_4</th>\n",
       "      <th>eig_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98304</th>\n",
       "      <td>0.434726</td>\n",
       "      <td>0.412707</td>\n",
       "      <td>1.337486</td>\n",
       "      <td>2.600392</td>\n",
       "      <td>0.786383</td>\n",
       "      <td>0.790090</td>\n",
       "      <td>0.534614</td>\n",
       "      <td>0.918914</td>\n",
       "      <td>0.885771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98305</th>\n",
       "      <td>0.489483</td>\n",
       "      <td>1.582053</td>\n",
       "      <td>1.468138</td>\n",
       "      <td>1.848136</td>\n",
       "      <td>0.636053</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.923485</td>\n",
       "      <td>0.809900</td>\n",
       "      <td>0.980728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98306</th>\n",
       "      <td>0.552244</td>\n",
       "      <td>1.910220</td>\n",
       "      <td>1.350259</td>\n",
       "      <td>2.726644</td>\n",
       "      <td>0.837142</td>\n",
       "      <td>0.838236</td>\n",
       "      <td>0.528075</td>\n",
       "      <td>0.861279</td>\n",
       "      <td>0.869879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98307</th>\n",
       "      <td>0.782566</td>\n",
       "      <td>0.077098</td>\n",
       "      <td>0.733530</td>\n",
       "      <td>1.724437</td>\n",
       "      <td>0.309145</td>\n",
       "      <td>0.960942</td>\n",
       "      <td>0.536709</td>\n",
       "      <td>0.598099</td>\n",
       "      <td>0.788312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98308</th>\n",
       "      <td>0.958658</td>\n",
       "      <td>0.665386</td>\n",
       "      <td>1.486674</td>\n",
       "      <td>2.051426</td>\n",
       "      <td>0.604664</td>\n",
       "      <td>0.901299</td>\n",
       "      <td>0.668710</td>\n",
       "      <td>0.910779</td>\n",
       "      <td>0.947638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131067</th>\n",
       "      <td>0.873763</td>\n",
       "      <td>0.138335</td>\n",
       "      <td>1.145569</td>\n",
       "      <td>1.334456</td>\n",
       "      <td>0.531536</td>\n",
       "      <td>0.528263</td>\n",
       "      <td>0.606136</td>\n",
       "      <td>0.973601</td>\n",
       "      <td>0.952599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131068</th>\n",
       "      <td>0.522992</td>\n",
       "      <td>0.140488</td>\n",
       "      <td>1.591347</td>\n",
       "      <td>0.859013</td>\n",
       "      <td>0.474287</td>\n",
       "      <td>0.873008</td>\n",
       "      <td>0.471576</td>\n",
       "      <td>0.996856</td>\n",
       "      <td>0.505303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131069</th>\n",
       "      <td>0.364947</td>\n",
       "      <td>1.185878</td>\n",
       "      <td>1.247024</td>\n",
       "      <td>2.592575</td>\n",
       "      <td>0.836996</td>\n",
       "      <td>0.772776</td>\n",
       "      <td>0.496226</td>\n",
       "      <td>0.869119</td>\n",
       "      <td>0.941350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131070</th>\n",
       "      <td>0.272736</td>\n",
       "      <td>0.054970</td>\n",
       "      <td>0.958174</td>\n",
       "      <td>2.089119</td>\n",
       "      <td>0.812896</td>\n",
       "      <td>0.630602</td>\n",
       "      <td>0.401596</td>\n",
       "      <td>0.997046</td>\n",
       "      <td>0.980887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131071</th>\n",
       "      <td>0.587418</td>\n",
       "      <td>0.160311</td>\n",
       "      <td>0.798260</td>\n",
       "      <td>2.138992</td>\n",
       "      <td>0.483895</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>0.376774</td>\n",
       "      <td>0.830098</td>\n",
       "      <td>0.809460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           phi_K     eig_0       eta      beta     eig_1     eig_2     eig_3  \\\n",
       "98304   0.434726  0.412707  1.337486  2.600392  0.786383  0.790090  0.534614   \n",
       "98305   0.489483  1.582053  1.468138  1.848136  0.636053  0.556604  0.923485   \n",
       "98306   0.552244  1.910220  1.350259  2.726644  0.837142  0.838236  0.528075   \n",
       "98307   0.782566  0.077098  0.733530  1.724437  0.309145  0.960942  0.536709   \n",
       "98308   0.958658  0.665386  1.486674  2.051426  0.604664  0.901299  0.668710   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "131067  0.873763  0.138335  1.145569  1.334456  0.531536  0.528263  0.606136   \n",
       "131068  0.522992  0.140488  1.591347  0.859013  0.474287  0.873008  0.471576   \n",
       "131069  0.364947  1.185878  1.247024  2.592575  0.836996  0.772776  0.496226   \n",
       "131070  0.272736  0.054970  0.958174  2.089119  0.812896  0.630602  0.401596   \n",
       "131071  0.587418  0.160311  0.798260  2.138992  0.483895  0.999408  0.376774   \n",
       "\n",
       "           eig_4     eig_5  \n",
       "98304   0.918914  0.885771  \n",
       "98305   0.809900  0.980728  \n",
       "98306   0.861279  0.869879  \n",
       "98307   0.598099  0.788312  \n",
       "98308   0.910779  0.947638  \n",
       "...          ...       ...  \n",
       "131067  0.973601  0.952599  \n",
       "131068  0.996856  0.505303  \n",
       "131069  0.869119  0.941350  \n",
       "131070  0.997046  0.980887  \n",
       "131071  0.830098  0.809460  \n",
       "\n",
       "[32768 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_kg_random_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test3 = datos_kg_random_copy[features]\n",
    "y_test3 = datos_kg_random_copy[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1024/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "metrs3 = data_processors.get_metrics(X_test3, y_test3, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos KG_random Julián:  {'R2': 0.8047776019818308, 'RMSE': np.float64(0.10328583619402947), 'MAE': np.float64(0.050953131663159346)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos KG_random Julián: \", metrs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "mets_combi = data_processors.get_metrics(X_combi, y_combi, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis datos combinatoriales:  {'R2': 0.9825540510514238, 'RMSE': np.float64(0.03808038970909831), 'MAE': np.float64(0.025816049447970797)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Mis datos combinatoriales: \", mets_combi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save(\"models/isotropico_act_custom.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
